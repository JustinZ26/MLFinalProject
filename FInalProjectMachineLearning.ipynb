{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "TnjOkm-8OkXG",
        "outputId": "77c6a1ce-d079-40f5-fcbf-40825e30541b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4cf3799f123cc44902.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4cf3799f123cc44902.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#emotion prediction from text\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, hamming_loss\n",
        "import gradio as gr\n",
        "\n",
        "# Load dataset\n",
        "splits = {'train': 'simplified/train-00000-of-00001.parquet'}\n",
        "df = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/\" + splits[\"train\"])\n",
        "\n",
        "emotion_labels = [\n",
        "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\",\n",
        "    \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\",\n",
        "    \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\",\n",
        "    \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\",\n",
        "    \"optimism\", \"pride\", \"realization\", \"relief\", \"remorse\",\n",
        "    \"sadness\", \"surprise\", \"neutral\"\n",
        "]\n",
        "\n",
        "index_to_emotion = {i: label for i, label in enumerate(emotion_labels)}\n",
        "\n",
        "mlb = MultiLabelBinarizer(classes=range(28))\n",
        "y = mlb.fit_transform(df['labels'])\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Placeholder for trained model\n",
        "model = None\n",
        "metrics_report = \"\"\n",
        "\n",
        "def train_model(test_size=0.2, max_iter=1000, random_state=42):\n",
        "    global model, metrics_report\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    model = MultiOutputClassifier(LogisticRegression(max_iter=max_iter))\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate standard classification report + other metrics\n",
        "    report = classification_report(\n",
        "        y_test, y_pred, target_names=[str(i) for i in range(28)]\n",
        "    )\n",
        "    micro_f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
        "    macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    hamming = hamming_loss(y_test, y_pred)\n",
        "\n",
        "    metrics_summary = f\"\"\"\n",
        "    Micro F1-score: {micro_f1:.4f}\n",
        "    Macro F1-score: {macro_f1:.4f}\n",
        "    Accuracy (Exact Match): {acc:.4f}\n",
        "    Hamming Loss: {hamming:.4f}\n",
        "    \"\"\"\n",
        "\n",
        "    # Save the full report\n",
        "    metrics_report = metrics_summary.strip() + \"\\n\\n\" + report\n",
        "\n",
        "    return \"Training Complete!\"\n",
        "\n",
        "def predict_emotions(text):\n",
        "    if model is None:\n",
        "        return \"Please train the model first.\", \"\"\n",
        "\n",
        "    vectorized = vectorizer.transform([text])\n",
        "    probas = model.predict_proba(vectorized)\n",
        "\n",
        "    result = {}\n",
        "    for i, emotion in enumerate(mlb.classes_):\n",
        "        prob_class_1 = probas[i][0][1]\n",
        "        result[emotion] = round(prob_class_1 * 100, 2)\n",
        "\n",
        "    sorted_result = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_result\n",
        "\n",
        "def predict_and_display(sentence):\n",
        "    predictions = predict_emotions(sentence)\n",
        "    if isinstance(predictions, str):\n",
        "        return predictions, \"\"\n",
        "\n",
        "    max_len = max(len(index_to_emotion[emo_id]) for emo_id, _ in predictions)\n",
        "    result = \"```\" + \"\\nEmotion Predictions:\\n\\n\"\n",
        "    for emo_id, score in predictions:\n",
        "        emo_name = index_to_emotion[emo_id]\n",
        "        result += f\"{emo_name.ljust(max_len)}  â†’ {score}%\\n\"\n",
        "    result += \"```\"\n",
        "    top_emotion = index_to_emotion[predictions[0][0]]\n",
        "    return result, top_emotion\n",
        "\n",
        "# Gradio App\n",
        "with gr.Blocks(title=\"Interactive Emotion Detector\", theme=gr.themes.Soft()) as demo:\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Emotion Detection\"):\n",
        "            gr.Markdown(\"## Emotion Detection\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    input_text = gr.Textbox(\n",
        "                        lines=3, placeholder=\"Enter a sentence...\", label=\"Input Sentence\"\n",
        "                    )\n",
        "                    submit_btn = gr.Button(\"Analyze Emotion\")\n",
        "                with gr.Column():\n",
        "                    output_text = gr.Markdown(label=\"Prediction Results\")\n",
        "                    top_emotion = gr.Label(label=\"Top Emotion\")\n",
        "            submit_btn.click(\n",
        "                fn=predict_and_display,\n",
        "                inputs=input_text,\n",
        "                outputs=[output_text, top_emotion]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Dataset\"):\n",
        "            gr.Markdown(\"## Dataset Information\")\n",
        "\n",
        "            def dataset_info():\n",
        "                df = pd.read_parquet(\"hf://datasets/google-research-datasets/go_emotions/simplified/train-00000-of-00001.parquet\")\n",
        "\n",
        "                total_samples = len(df)\n",
        "                emotions = sorted(set(e for label in df['labels'] for e in label))\n",
        "                emotion_names = [emotion_labels[i] for i in emotions]\n",
        "\n",
        "                # Count distribution\n",
        "                all_labels = [emotion_labels[i] for sublist in df['labels'] for i in sublist]\n",
        "                label_counts = pd.Series(all_labels).value_counts().sort_index()\n",
        "                label_df = pd.DataFrame({\n",
        "                    \"Emotion\": label_counts.index,\n",
        "                    \"Count\": label_counts.values\n",
        "                })\n",
        "\n",
        "                stats = f\"\"\"\n",
        "                    **Total Samples**: {total_samples}\n",
        "                    **Emotion Classes**: {', '.join(emotion_names)}\n",
        "                    \"\"\"\n",
        "\n",
        "                return stats, label_df\n",
        "\n",
        "            stats_display = gr.Markdown()\n",
        "            dist_table = gr.Dataframe(headers=[\"Emotion\", \"Count\"], interactive=False)\n",
        "\n",
        "            load_btn = gr.Button(\"Load Dataset Info\")\n",
        "            load_btn.click(fn=dataset_info, inputs=[], outputs=[stats_display, dist_table])\n",
        "\n",
        "\n",
        "        with gr.Tab(\"EDA\"):\n",
        "            gr.Markdown(\"## Exploratory Data Analysis\")\n",
        "\n",
        "            eda_btn = gr.Button(\"Run EDA\")\n",
        "\n",
        "            eda_output = gr.Plot(label=\"EDA Output\")\n",
        "\n",
        "            def run_eda():\n",
        "                import matplotlib.pyplot as plt\n",
        "                from collections import Counter\n",
        "                import re\n",
        "\n",
        "                # Define the label map inside the function\n",
        "                label_map = [\n",
        "                    'admiration', 'amusement', 'anger', 'annoyance', 'approval',\n",
        "                    'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
        "                    'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
        "                    'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism',\n",
        "                    'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise',\n",
        "                    'neutral'\n",
        "                ]\n",
        "\n",
        "                fig, axs = plt.subplots(2, 2, figsize=(18, 10))\n",
        "\n",
        "                # Label distribution\n",
        "                label_counts = df['labels'].explode().value_counts().sort_index()\n",
        "                axs[0, 0].bar(label_map, label_counts)\n",
        "                axs[0, 0].set_title(\"Label Frequency Distribution\")\n",
        "                axs[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "                # Labels per example\n",
        "                df['num_labels'] = df['labels'].apply(len)\n",
        "                df['num_labels'].value_counts().sort_index().plot(kind='bar', ax=axs[0, 1])\n",
        "                axs[0, 1].set_title(\"Number of Labels per Example\")\n",
        "\n",
        "                # Text length distribution\n",
        "                df['text_length'] = df['text'].apply(len)\n",
        "                df['text_length'].hist(bins=50, ax=axs[1, 0])\n",
        "                axs[1, 0].set_title(\"Distribution of Text Lengths\")\n",
        "                axs[1, 0].set_xlabel(\"Text Length (characters)\")\n",
        "                axs[1, 0].set_ylabel(\"Frequency\")\n",
        "\n",
        "                # Most common words\n",
        "                all_words = \" \".join(df['text']).lower()\n",
        "                tokens = re.findall(r'\\b\\w+\\b', all_words)\n",
        "                common_words = Counter(tokens).most_common(20)\n",
        "                words, freqs = zip(*common_words)\n",
        "                axs[1, 1].bar(words, freqs)\n",
        "                axs[1, 1].set_title(\"Top 20 Most Common Words\")\n",
        "                axs[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "                plt.tight_layout()\n",
        "                return fig\n",
        "\n",
        "            eda_btn.click(fn=run_eda, inputs=[], outputs=eda_output)\n",
        "\n",
        "\n",
        "\n",
        "        with gr.Tab(\"Train Model\"):\n",
        "            gr.Markdown(\"## Train Your Emotion Model\")\n",
        "            test_size = gr.Slider(0.1, 0.5, step=0.05, value=0.2, label=\"Test Size\")\n",
        "            max_iter = gr.Slider(100, 5000, step=100, value=1000, label=\"Max Iterations\")\n",
        "            random_state = gr.Number(value=42, label=\"Random State\")\n",
        "            train_button = gr.Button(\"Train Model\")\n",
        "            train_status = gr.Textbox(label=\"Training Status\")\n",
        "            train_button.click(\n",
        "                fn=train_model,\n",
        "                inputs=[test_size, max_iter, random_state],\n",
        "                outputs=train_status\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Results\"):\n",
        "            gr.Markdown(\"## Evaluation Metrics\")\n",
        "            results_output = gr.Markdown(label=\"Classification Report\")\n",
        "\n",
        "            def get_report():\n",
        "                return \"```\\n\" + metrics_report + \"\\n```\"\n",
        "\n",
        "            refresh_btn = gr.Button(\"Refresh Report\")\n",
        "            refresh_btn.click(\n",
        "                fn=get_report,\n",
        "                inputs=[],\n",
        "                outputs=results_output\n",
        "            )\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-PUI9-0UmFM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}